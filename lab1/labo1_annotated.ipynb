{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02418832",
   "metadata": {},
   "source": [
    "# Lab 1 : Compute Pipeline (wgpu + WGSL) - version comment√©e (li√©e au projet Cloth)\n",
    "\n",
    "Objectif du lab :\n",
    "- construire un **compute pipeline**\n",
    "- comprendre **dispatch/workgroups/threads**\n",
    "- utiliser des **storage buffers** (lecture/√©criture)\n",
    "- connecter CPU ‚Üí GPU avec **bind groups**\n",
    "- r√©cup√©rer un r√©sultat GPU vers Python\n",
    "\n",
    "Lien direct avec le projet final (Cloth Simulation) :\n",
    "- le tissu = un ensemble de **vertices** (positions, vitesses, masses)\n",
    "- √† chaque frame : un compute shader met √† jour les √©tats (**forces ‚Üí vitesses ‚Üí positions**)\n",
    "- exactement la m√™me m√©canique que ce lab : **buffers + bind groups + dispatch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb85486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Petit helper pour mesurer le temps CPU c√¥t√© Python\n",
    "class Timer:\n",
    "    def __init__(self, msg: str):\n",
    "        self.msg = msg\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time.perf_counter()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        print(f\"{self.msg}: {time.perf_counter() - self.start:.6f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bce11c",
   "metadata": {},
   "source": [
    "## 1) Donn√©es CPU (numpy) ‚Üí Buffer GPU\n",
    "\n",
    "Dans ce lab on fait un calcul simple :\n",
    "- entr√©e `data0[i]`\n",
    "- sortie `data1[i] = data0[i] * data0[i]`\n",
    "\n",
    "üéØ **Projet Cloth :** remplace `data0`/`data1` par des buffers :\n",
    "- `positions[i]` et `velocities[i]` (read_write)\n",
    "- √©ventuellement un buffer `springs[]` ou des buffers de param√®tres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94ee535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taille du tableau\n",
    "N = 1024  # petit pour le lab (rapide). Projet cloth: N = nb_vertices.\n",
    "assert N % 64 == 0, \"Ici on dispatch par blocs de 64 threads (workgroup_size=64).\"\n",
    "\n",
    "# Entr√©e CPU\n",
    "data0 = np.arange(N, dtype=np.int32)\n",
    "\n",
    "# Note: on ne cr√©e pas data1 CPU, car la sortie sera √©crite par le GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a1e013",
   "metadata": {},
   "source": [
    "## 2) Initialisation wgpu : Adapter + Device\n",
    "\n",
    "- **Adapter** = carte/driver choisi (GPU)\n",
    "- **Device** = \"contexte\" GPU, pour cr√©er buffers/pipelines/commandes\n",
    "- **Queue** = file d'envoi des commandes (submit)\n",
    "\n",
    "üéØ **Projet Cloth :** m√™me init, puis tu r√©utilises le device/queue toute la simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08466a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wgpu import gpu\n",
    "\n",
    "# Choix de l'adapter (high-performance si possible)\n",
    "adapter = gpu.request_adapter_sync(power_preference=\"high-performance\")\n",
    "device = adapter.request_device_sync()\n",
    "\n",
    "queue = device.queue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f6889",
   "metadata": {},
   "source": [
    "## 3) Cr√©ation des buffers GPU\n",
    "\n",
    "Points cl√©s :\n",
    "- **BufferUsage.STORAGE** : accessible depuis le compute shader (lecture/√©criture)\n",
    "- **BufferUsage.COPY_DST** : permet d'envoyer des donn√©es CPU ‚Üí GPU\n",
    "- **BufferUsage.COPY_SRC** : permet de lire des donn√©es GPU ‚Üí CPU\n",
    "\n",
    "üéØ **Projet Cloth :**\n",
    "- positions/velocities = STORAGE | COPY_DST | COPY_SRC (souvent)\n",
    "- param√®tres \"uniform\" possibles, ou storage pour grands tableaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e115bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wgpu import BufferUsage\n",
    "\n",
    "# Buffer d'entr√©e (read-only dans le shader)\n",
    "buffer0 = device.create_buffer_with_data(\n",
    "    data=data0.tobytes(), # on cr√©e et on initialise en m√™me temps c'est quoi tobytes() ? \n",
    "    # tobytes() convertit un tableau numpy en une s√©quence d'octets, n√©cessaire pour cr√©er un buffer GPU\n",
    "    usage=BufferUsage.STORAGE | BufferUsage.COPY_SRC | BufferUsage.COPY_DST,\n",
    ")\n",
    "\n",
    "# dans un projet r√©el, le buffer sert √† stocker des donn√©es de vertex (positions, couleurs, normales, etc.).\n",
    "# c'est quoi vertex? vertex = sommet en fran√ßais\n",
    "# dans un projet de simulation physique (cloth, fluides, etc.),\n",
    "# buffer d'entr√©e stocke des positions, vitesses, forces, etc.\n",
    "# buffer de sortie stocke les nouvelles positions, vitesses, etc.\n",
    "# utiliser des **storage buffers** (lecture/√©criture) pour cela. \n",
    "# quand on utilise uniforms, on ne peut pas stocker autant de donn√©es.\n",
    "# pourquoi on met buffer0 en COPY_DST? pour pouvoir uploader des donn√©es CPU->GPU plus tard.\n",
    "# pourquoi on met buffer0 en entr√©e ? STORAGE? pour que le shader compute puisse lire les donn√©es.\n",
    "# \n",
    "\n",
    "# Buffer de sortie (√©crit par le shader)\n",
    "buffer1 = device.create_buffer(\n",
    "    size=data0.nbytes, # m√™me taille que buffer0\n",
    "    # pas d'initialisation, on va √©crire dedans depuis le shader\n",
    "    # c'est quoi nbytes?\n",
    "    # nbytes donne la taille en octets du tableau numpy, n√©cessaire pour allouer le buffer GPU\n",
    "    usage=BufferUsage.STORAGE | BufferUsage.COPY_SRC | BufferUsage.COPY_DST,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a907ea2",
   "metadata": {},
   "source": [
    "## 4) WGSL Compute Shader\n",
    "\n",
    "Le shader re√ßoit :\n",
    "- `@group(0) @binding(0)` : buffer0 (read)\n",
    "- `@group(0) @binding(1)` : buffer1 (read_write)\n",
    "\n",
    "Le thread global est donn√© par :\n",
    "- `@builtin(global_invocation_id) gid`\n",
    "\n",
    "Dans ce lab :\n",
    "- **1 thread = 1 √©l√©ment i**\n",
    "- `i = gid.x`\n",
    "\n",
    "üéØ **Projet Cloth :**\n",
    "- souvent **1 thread = 1 vertex**\n",
    "- `i = gid.x`\n",
    "- puis tu lis/√©cris `positions[i]`, `velocities[i]`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a322ef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Lab 1 ‚Äî Compute shader (WGSL) ‚Äî version comment√©e\n",
      "// Objectif: data1[i] = data0[i]^2\n",
      "//\n",
      "// LIEN PROJET CLOTH:\n",
      "// - data0/data1 seraient remplac√©s par positions/velocities/springs/params\n",
      "// - 1 thread GPU = 1 vertex (souvent)\n",
      "// - gid.x sert d'index \"i\" dans tes buffers\n",
      "\n",
      "@group(0) @binding(0)\n",
      "var<storage, read> data0: array<i32>;\n",
      "\n",
      "@group(0) @binding(1)\n",
      "var<storage, read_write> data1: array<i32>;\n",
      "\n",
      "@compute @workgroup_size(64)\n",
      "fn main(@builtin(global_invocation_id) gid: vec3<u32>) {\n",
      "    // Index global du thread (sur l'axe X)\n",
      "    let i: u32 = gid.x;\n",
      "\n",
      "    // S√©curit√©: si on dispatch un peu trop, on √©vite d'√©crire hors buffer\n",
      "    // (Pour le lab on a choisi N multiple de 64 donc √ßa ne d√©clenche pas.)\n",
      "    if (i >= arrayLength(&data0)) {\n",
      "        return;\n",
      "    }\n",
      "\n",
      "    // Calcul jouet\n",
      "    data1[i] = data0[i] * data0[i];\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# On charge le shader depuis le fichier compute.wgsl fourni\n",
    "# a quoi sert le shader?\n",
    "# le shader compute est un programme qui s'ex√©cute sur le GPU pour effectuer des calculs parall√®les.\n",
    "# il lit les donn√©es d'entr√©e depuis des buffers, effectue des calculs, et √©crit\n",
    "shader_code = open(\"compute_annotated.wgsl\", \"r\", encoding=\"utf-8\").read()\n",
    "print(shader_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646c94f8",
   "metadata": {},
   "source": [
    "## 5) Bind Group Layout + Bind Group\n",
    "\n",
    "- Le **BindGroupLayout** d√©crit *la forme* : \"binding 0 = storage buffer, binding 1 = storage buffer\"\n",
    "- Le **BindGroup** met les *vrais buffers* derri√®re ces bindings.\n",
    "\n",
    "üéØ **Projet Cloth :**\n",
    "- tu auras plusieurs bindings : positions, velocities, springs, params‚Ä¶\n",
    "- et parfois plusieurs bind groups (group(0), group(1), ‚Ä¶) si tu veux s√©parer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1826be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wgpu import ShaderStage, BufferBindingType\n",
    "\n",
    "# Layout des ressources visibles par le shader (group=0)\n",
    "bind_group_layout = device.create_bind_group_layout(\n",
    "    entries=[\n",
    "        {  # binding 0 -> buffer0 (read)\n",
    "            \"binding\": 0,\n",
    "            \"visibility\": ShaderStage.COMPUTE,\n",
    "            \"buffer\": {\"type\": BufferBindingType.read_only_storage},\n",
    "        },\n",
    "        {  # binding 1 -> buffer1 (read_write)\n",
    "            \"binding\": 1,\n",
    "            \"visibility\": ShaderStage.COMPUTE,\n",
    "            \"buffer\": {\"type\": BufferBindingType.storage},\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Cr√©ation du bind group (association des buffers aux bindings)\n",
    "bind_group = device.create_bind_group(\n",
    "    layout=bind_group_layout,\n",
    "    entries=[\n",
    "        {\"binding\": 0, \"resource\": {\"buffer\": buffer0, \"offset\": 0, \"size\": data0.nbytes}},\n",
    "        {\"binding\": 1, \"resource\": {\"buffer\": buffer1, \"offset\": 0, \"size\": data0.nbytes}},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87ceb8f",
   "metadata": {},
   "source": [
    "## 6) Compute Pipeline (shader module ‚Üí pipeline)\n",
    "\n",
    "- `create_shader_module` compile le WGSL\n",
    "- `create_compute_pipeline` cr√©e le pipeline avec l'entr√©e `entry_point=\"main\"`\n",
    "- `pipeline_layout` relie les bind groups\n",
    "\n",
    "üéØ **Projet Cloth :**\n",
    "- tu gardes la m√™me structure\n",
    "- tu changes juste les bindings et le code WGSL (forces + int√©gration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85604ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation WGSL -> shader module\n",
    "shader_module = device.create_shader_module(code=shader_code)\n",
    "\n",
    "# Pipeline layout (liste des bind group layouts)\n",
    "# c'est quoi un pipeline layout?\n",
    "# un pipeline layout d√©finit la structure des ressources (bind groups) utilis√©es par le pipeline.\n",
    "pipeline_layout = device.create_pipeline_layout(bind_group_layouts=[bind_group_layout])\n",
    "\n",
    "# Compute pipeline\n",
    "# cest quoi un pipeline?\n",
    "# un pipeline est une configuration qui d√©finit comment les shaders sont ex√©cut√©s sur le GPU,\n",
    "# incluant les ressources utilis√©es (buffers, textures, etc.)\n",
    "pipeline = device.create_compute_pipeline(\n",
    "    layout=pipeline_layout,\n",
    "    compute={\"module\": shader_module, \"entry_point\": \"main\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb61526",
   "metadata": {},
   "source": [
    "## 7) Command Encoder + Compute Pass + Dispatch\n",
    "\n",
    "√âtapes typiques :\n",
    "1) `create_command_encoder()`\n",
    "2) `begin_compute_pass()`\n",
    "3) `set_pipeline()`\n",
    "4) `set_bind_group()`\n",
    "5) `dispatch_workgroups()`\n",
    "6) `end()` puis `queue.submit(...)`\n",
    "\n",
    "**Calcul du dispatch**\n",
    "- shader: `@workgroup_size(64)`\n",
    "- donc pour traiter N √©l√©ments : `dispatch_workgroups(N/64, 1, 1)`\n",
    "\n",
    "üéØ **Projet Cloth :**\n",
    "- N = nb_vertices\n",
    "- parfois tu fais plusieurs dispatch (ex: forces puis int√©gration) ou plusieurs passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b770be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute Pipeline (dispatch): 0.123572 s\n"
     ]
    }
   ],
   "source": [
    "from wgpu import GPUCommandEncoder, GPUComputePassEncoder\n",
    "\n",
    "# Execution du pipeline compute\n",
    "with Timer(\"Compute Pipeline (dispatch)\"):\n",
    "    # Enregistrement des commandes\n",
    "    command_encoder: GPUCommandEncoder = device.create_command_encoder()\n",
    "    # cr√©ation d'une passe compute \n",
    "    compute_pass: GPUComputePassEncoder = command_encoder.begin_compute_pass()\n",
    "    # Configurer la passe compute\n",
    "    compute_pass.set_pipeline(pipeline)\n",
    "    # lier les ressources (buffers) au pipeline\n",
    "    compute_pass.set_bind_group(0, bind_group)\n",
    "\n",
    "    # Dispatch: N √©l√©ments, workgroup_size=64 => N/64 workgroups sur X\n",
    "    compute_pass.dispatch_workgroups(N // 64, 1, 1)\n",
    "\n",
    "    compute_pass.end()\n",
    "\n",
    "    # Envoi au GPU\n",
    "    queue.submit([command_encoder.finish()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70738bf",
   "metadata": {},
   "source": [
    "## 8) Lecture du r√©sultat GPU ‚Üí CPU\n",
    "\n",
    "`device.queue.read_buffer(buffer1)` permet de r√©cup√©rer la sortie.\n",
    "\n",
    "üéØ **Projet Cloth :**\n",
    "- en g√©n√©ral tu ne lis pas tout √† chaque frame (trop lent)\n",
    "- tu lis seulement pour debug, capture, ou export.\n",
    "- sinon tu affiches le tissu directement depuis les buffers GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4cbaaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK ? True\n",
      "Extrait: [ 0  1  4  9 16 25 36 49 64 81]\n"
     ]
    }
   ],
   "source": [
    "# R√©cup√©ration CPU\n",
    "out: memoryview = device.queue.read_buffer(buffer1)\n",
    "result = np.frombuffer(out.cast(\"i\"), dtype=np.int32)\n",
    "\n",
    "# V√©rification\n",
    "expected = data0 * data0\n",
    "print(\"OK ?\", np.all(result == expected))\n",
    "print(\"Extrait:\", result[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd1d60f",
   "metadata": {},
   "source": [
    "GPU : petite puce dans la carte graphique dans le pc\n",
    "API: code pour interagir (dessiner et faire de calcul)\n",
    "\n",
    "- on fait d'abord le model \n",
    "- obj : format text avec plein de lignes\n",
    "- space local centr√© au milieu\n",
    "- on met une petite camera \n",
    "- sa position (2D sur canvas)\n",
    "\n",
    "- un GPU fait que de trinagles\n",
    "- on fait de pixel\n",
    "- couleur de pixel\n",
    "- positon, eclairage\n",
    "- couleur final apr√®s superpositon\n",
    "\n",
    "![image.png]\n",
    "(attachment:image.png)\n",
    "\n",
    "- gpu fait tout seul:\n",
    "    - vertex: prog qui s'execute pour chaque en parrall\n",
    "    - fragment shader : () il renvoi la couleur \n",
    "    - \n",
    "\n",
    "- WEBgl : \n",
    "- a chaque fram on renitialise tout et on recommence \n",
    "- \n",
    "\n",
    "nouvel API :\n",
    "\n",
    "dessiner et faire de calcul\n",
    "\n",
    "vertex sahder et fragment shader\n",
    "\n",
    "\n",
    "on a un seul appel \n",
    "bingroup\n",
    "\n",
    "shader: compute shader (wgsl)\n",
    "\n",
    "on declare un ou plusieur tableau en sortie + les index avec une fonction qui prends "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
